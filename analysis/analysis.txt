Hunter Gregory
hlg16

Copy/Paste results from PercolationStats using PercolationDFSFast

simulation data for 20 trials
grid	mean	stddev	time
100		0.593	0.014	0.237
200		0.591	0.010	0.278
400		0.590	0.006	0.967
800		0.594	0.004	7.110

Stack Overflow for rest


Copy/Paste results from PercolationStats using PercolationBFS

simulation data for 20 trials
grid	mean	stddev	time
100		0.593	0.014	0.165
200		0.591	0.010	0.203
400		0.590	0.006	1.069
800		0.594	0.004	6.646
1600	0.592	0.002	33.489
3200	0.593	0.001	207.325


Copy/Paste results from PercolationStats using PercolationUF

simulation data for 20 trials
grid	mean	stddev	time
100		0.593	0.014	0.126
200		0.591	0.010	0.162
400		0.590	0.006	0.956
800		0.594	0.004	5.813
1600	0.592	0.002	27.309
3200	0.593	0.001	143.404


1. How does doubling the grid size affect running time (keeping # trials fixed)

Doubling the grid size quintuples the runtime. 


2. How does doubling the number of trials affect running time.

simulation data for 40 trials
grid	mean	stddev	time
100		0.594	0.015	0.180
200		0.591	0.009	0.271
400		0.591	0.005	1.961
800		0.593	0.004	12.586
1600	0.593	0.002	54.558
3200	0.593	0.001	294.938

Doubling the amount of trials seems to increase runtime by a factor of 5.


3. Estimate the largest grid size you can run in 24 hours with 20 trials. Explain your reasoning.

The answers to the last two questions suggest that the runtime of PercolationUF is O(T*N^2), where
T is the number of trials and N is the grid size.

Take simulated datum for PercolationUF, grid size = 3200, trials = 20.
24 hours = 86,400 seconds

We can find the approximate largest grid size that can run in 24 hours with 20 trials by solving this equation:
	grid size = 100 * 2^k <--> runtime = 143.404 * 5^k <= 86,400
	
	So then 5^k <= 86,257, so then k <= 7.06
	
	--> 100 * 2^k <= 13,357
	
So a grid size of about 13,300.

